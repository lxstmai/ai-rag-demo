"""
–ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã
"""
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from core.indexer import WebsiteIndexer
from core.retriever import ContextRetriever
from core.llm_client import LLMClient, RAGPipeline
from utils.config import EMBEDDING_MODEL, CHROMA_DB_PATH, CHROMA_COLLECTION_NAME

def main():
    print("üöÄ RAG System Demo")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    print("üì¶ Loading models...")
    from sentence_transformers import SentenceTransformer
    import chromadb
    
    embedding_model = SentenceTransformer(EMBEDDING_MODEL)
    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    chroma_collection = chroma_client.get_or_create_collection(name=CHROMA_COLLECTION_NAME)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
    indexer = WebsiteIndexer(embedding_model, chroma_collection)
    retriever = ContextRetriever(embedding_model, chroma_collection)
    
    # Example 1: Website Indexing
    print("\nüìÑ Example 1: Website Indexing")
    website_url = "https://example.com"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π —Å–∞–π—Ç
    result = indexer.index_website(website_url, max_pages=3)
    print(f"Indexing result: {result}")
    
    # Example 2: Context Search
    print("\nüîç Example 2: Relevant Context Search")
    query = "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç?"
    context_result = retriever.find_relevant_context(query)
    print(f"Found .* relevant fragments")
    
    if context_result.get('chunks'):
        print("First fragment:")
        print(f"  Text: {context_result['chunks'][0]['text'][:100]}...")
        print(f"  Similarity: {context_result['chunks'][0]['similarity']:.2f}")
    
    # Example 3: Full RAG Pipeline (–µ—Å–ª–∏ LLM –¥–æ—Å—Ç—É–ø–µ–Ω)
    print("\nü§ñ Example 3: Full RAG Pipeline")
    try:
        llm_client = LLMClient("deepseek")
        rag_pipeline = RAGPipeline(retriever, llm_client)
        
        answer_result = rag_pipeline.ask(query)
        print(f"Answer: {answer_result['answer']}")
        print(f"Sources: {answer_result['sources']}")
        
    except Exception as e:
        print(f"LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        print("–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLM —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ API –∫–ª—é—á –≤ .env —Ñ–∞–π–ª–µ")
    
    # Example 4: System Statistics
    print("\nüìä Example 4: System Statistics")
    stats = retriever.get_collection_info()
    print(f"Total documents: {stats.get('total_documents', 0)}")
    print(f"URL examples: {stats.get('sample_urls', [])}")

if __name__ == "__main__":
    main()
