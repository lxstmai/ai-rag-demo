"""
–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã
"""
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from core.indexer import WebsiteIndexer
from core.retriever import ContextRetriever
from core.llm_client import LLMClient, RAGPipeline

def demonstrate_advanced_features():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã"""
    print("üî¨ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ RAG —Å–∏—Å—Ç–µ–º—ã")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ basic_usage.py)
    from sentence_transformers import SentenceTransformer
    import chromadb
    from utils.config import EMBEDDING_MODEL, CHROMA_DB_PATH, CHROMA_COLLECTION_NAME
    
    embedding_model = SentenceTransformer(EMBEDDING_MODEL)
    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    chroma_collection = chroma_client.get_or_create_collection(name=CHROMA_COLLECTION_NAME)
    
    retriever = ContextRetriever(embedding_model, chroma_collection)
    
    # 1. Keyword Search
    print("\nüîë Keyword Search")
    keywords = ["–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏", "–∞–ª–≥–æ—Ä–∏—Ç–º—ã"]
    keyword_result = retriever.search_by_keywords(keywords, top_k=3)
    print(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {keyword_result.get('total_found', 0)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    # 2. Similar Documents Search
    print("\nüîç Similar Documents Search")
    try:
        # –ü–æ–ª—É—á–∞–µ–º ID –ø–µ—Ä–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        all_docs = chroma_collection.get(limit=1, include=['metadatas'])
        if all_docs['ids']:
            doc_id = all_docs['ids'][0]
            similar_docs = retriever.get_similar_documents(doc_id, top_k=3)
            print(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {similar_docs.get('total_found', 0)}")
            
            if similar_docs.get('similar_documents'):
                print("–°–∞–º—ã–π –ø–æ—Ö–æ–∂–∏–π –¥–æ–∫—É–º–µ–Ω—Ç:")
                doc = similar_docs['similar_documents'][0]
                print(f"  –°—Ö–æ–∂–µ—Å—Ç—å: {doc['similarity']:.2f}")
                print(f"  –¢–µ–∫—Å—Ç: {doc['text'][:100]}...")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
    
    # 3. –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞
    print("\nüìà –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞")
    test_queries = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç?",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏?",
        "–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è",
        "–ê–ª–≥–æ—Ä–∏—Ç–º—ã –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
    ]
    
    for query in test_queries:
        result = retriever.find_relevant_context(query, top_k=2)
        if result.get('chunks'):
            avg_similarity = sum(chunk['similarity'] for chunk in result['chunks']) / len(result['chunks'])
            print(f"  '{query}': —Å—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å {avg_similarity:.2f}")
        else:
            print(f"  '{query}': —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    # 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ LLM
    print("\nü§ñ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤")
    test_query = "–û–±—ä—è—Å–Ω–∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º DeepSeek (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
    try:
        deepseek_client = LLMClient("deepseek")
        deepseek_pipeline = RAGPipeline(retriever, deepseek_client)
        deepseek_result = deepseek_pipeline.ask(test_query)
        print(f"DeepSeek –æ—Ç–≤–µ—Ç: {deepseek_result['answer'][:100]}...")
    except Exception as e:
        print(f"DeepSeek –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º OpenAI (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
    try:
        openai_client = LLMClient("openai")
        openai_pipeline = RAGPipeline(retriever, openai_client)
        openai_result = openai_pipeline.ask(test_query)
        print(f"OpenAI –æ—Ç–≤–µ—Ç: {openai_result['answer'][:100]}...")
    except Exception as e:
        print(f"OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    # 5. –≠–∫—Å–ø–æ—Ä—Ç –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
    print("\nüìä –≠–∫—Å–ø–æ—Ä—Ç –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
    collection_info = retriever.get_collection_info()
    print(f"–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {collection_info.get('total_documents', 0)}")
    print(f"  –ö–æ–ª–ª–µ–∫—Ü–∏—è: {collection_info.get('collection_name', 'unknown')}")
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    try:
        all_metadata = chroma_collection.get(include=['metadatas'])
        if all_metadata['metadatas']:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            sources = {}
            for metadata in all_metadata['metadatas']:
                if 'url' in metadata:
                    url = metadata['url']
                    sources[url] = sources.get(url, 0) + 1
            
            print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(sources)}")
            print("  –¢–æ–ø-3 –∏—Å—Ç–æ—á–Ω–∏–∫–∞:")
            for url, count in sorted(sources.items(), key=lambda x: x[1], reverse=True)[:3]:
                print(f"    {url}: {count} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")

def benchmark_performance():
    """–ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã"""
    print("\n‚ö° –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    
    import time
    from sentence_transformers import SentenceTransformer
    import chromadb
    from utils.config import EMBEDDING_MODEL, CHROMA_DB_PATH, CHROMA_COLLECTION_NAME
    
    embedding_model = SentenceTransformer(EMBEDDING_MODEL)
    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    chroma_collection = chroma_client.get_or_create_collection(name=CHROMA_COLLECTION_NAME)
    retriever = ContextRetriever(embedding_model, chroma_collection)
    
    # –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞
    test_queries = [
        "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
        "–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏",
        "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
        "–≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
        "–∞–ª–≥–æ—Ä–∏—Ç–º—ã"
    ]
    
    total_time = 0
    for query in test_queries:
        start_time = time.time()
        result = retriever.find_relevant_context(query)
        end_time = time.time()
        
        query_time = end_time - start_time
        total_time += query_time
        print(f"  '{query}': {query_time:.3f}—Å, –Ω–∞–π–¥–µ–Ω–æ {result.get('total_found', 0)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    avg_time = total_time / len(test_queries)
    print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {avg_time:.3f}—Å")

if __name__ == "__main__":
    demonstrate_advanced_features()
    benchmark_performance()
