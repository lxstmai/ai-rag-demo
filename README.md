# ğŸ¤– AI RAG System Demo

A demonstration project of a RAG (Retrieval-Augmented Generation) system for creating AI assistants based on web content.

## âœ¨ Features

- **ğŸŒ Website Indexing**: Automatic parsing and extraction of text content
- **ğŸ” Semantic Search**: Search for relevant information using vector embeddings
- **ğŸ¤– AI Assistant**: Generate answers based on found context
- **ğŸŒ Web Interface**: Intuitive API and web interface for interaction
- **ğŸ“Š Monitoring**: System statistics and search quality

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ core/              # Core system logic
â”‚   â”œâ”€â”€ indexer.py     # Website indexing and parsing
â”‚   â”œâ”€â”€ retriever.py   # Relevant context search
â”‚   â””â”€â”€ llm_client.py  # LLM integration (DeepSeek/OpenAI)
â”œâ”€â”€ web/               # Web interface
â”‚   â””â”€â”€ app.py         # Flask application with API
â””â”€â”€ utils/             # Utility functions
    â”œâ”€â”€ text_processing.py
    â””â”€â”€ config.py
```

## ğŸ› ï¸ Technologies

- **Python 3.8+**
- **Flask** - web framework
- **ChromaDB** - vector database
- **Sentence Transformers** - embedding models
- **BeautifulSoup** - HTML parsing
- **Requests** - HTTP client

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repository-url>
cd ai_rag_demo

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows
```

### 2. Dependencies

```bash
# Install dependencies
pip install -r requirements.txt
```

### 3. Configuration

```bash
# Copy environment configuration
cp .env.example .env

# Edit .env file and add your API keys
# DEEPSEEK_API_KEY=your_deepseek_api_key
# OPENAI_API_KEY=your_openai_api_key
```

### 4. Run Demo

```bash
# Start the demo
python run_demo.py
```

Open your browser: http://localhost:5000

## ğŸ“– Usage Examples

### Basic Usage

```python
from src.core.indexer import WebsiteIndexer
from src.core.retriever import ContextRetriever
from src.core.llm_client import RAGPipeline

# Initialize components
indexer = WebsiteIndexer(embedding_model, chroma_collection)
retriever = ContextRetriever(embedding_model, chroma_collection)
rag_pipeline = RAGPipeline(retriever, llm_client)

# Index a website
result = indexer.index_website("https://example.com", max_pages=5)

# Search and generate answer
response = rag_pipeline.query("What is this website about?")
print(response['answer'])
```

### API Usage

```bash
# Index a website
curl -X POST http://localhost:5000/api/index \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com", "max_pages": 5}'

# Query the system
curl -X POST http://localhost:5000/api/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What is artificial intelligence?"}'
```

## ğŸ§ª Testing

```bash
# Run tests
python -m pytest tests/ -v
```

## ğŸ“š Documentation

- [Quick Start Guide](QUICK_START.md) - detailed setup instructions
- [API Documentation](docs/API.md) - complete API reference
- [Architecture Overview](docs/ARCHITECTURE.md) - system architecture
- [Deployment Guide](DEPLOYMENT.md) - production deployment

## ğŸ”§ Configuration

### Environment Variables

- `DEEPSEEK_API_KEY` - DeepSeek API key
- `OPENAI_API_KEY` - OpenAI API key
- `EMBEDDING_MODEL` - Sentence transformer model
- `CHROMA_DB_PATH` - ChromaDB storage path
- `CHUNK_SIZE` - Text chunk size for indexing
- `TOP_K_RESULTS` - Number of search results

### Model Configuration

The system uses `sentence-transformers/all-MiniLM-L6-v2` by default for embeddings. You can change this in the configuration.

## ğŸš€ Deployment

### Local Development

```bash
python run_demo.py
```

### Production Deployment

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed production deployment instructions.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ†˜ Support

If you encounter any issues:

1. Check the [troubleshooting guide](DEPLOYMENT.md#troubleshooting)
2. Review the logs
3. Create an issue on GitHub

## ğŸ™ Acknowledgments

- [ChromaDB](https://github.com/chroma-core/chroma) for vector storage
- [Sentence Transformers](https://github.com/UKPLab/sentence-transformers) for embeddings
- [Flask](https://flask.palletsprojects.com/) for the web framework
